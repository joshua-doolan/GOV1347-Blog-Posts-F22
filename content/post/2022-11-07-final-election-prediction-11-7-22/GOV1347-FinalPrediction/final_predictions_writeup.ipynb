{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final House Prediction - 11/7/22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Overviews & Innovations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For my final prediction, I created two separate predictive models:\n",
    "\n",
    "1. A \"lite\" model which produces a national level prediction based on incumbency, economic, and polling factors only\n",
    "2. A \"deluxe\" model which produces a district-level prediction that attempts to improve off the gold-standard 538 prediction\n",
    "\n",
    "Before jumping into the details of each of the models, I want to provide what I believe are the main innovations of my models, and whether they are predictive. \n",
    "\n",
    "1. Lite: Consumer Sentiment Economic Data -- this seems predictive! \n",
    "- Many have described the 2022 economy as unique, because of low unemployment, but high inflation, with rising wages and prives alike. Previously, to understand this, people have used Real Disposable Income as a proxy for inflation-adjusted tangible growth, but based on my prior economic work, this seems only marginally better than GDP. Furthermore, others have used gas prices as a proxy for tangible consumer perception of the economy, to more mixed results. Therefore, I use the University of Michigan's consumer sentiment survey, and found that this seems more predictive than other economic indicators.\n",
    "2. Delixe: District-Level Donation Data -- so far, not predictive, but I believe to be promising. \n",
    "- For my deluxe model, I came in with the presumption that 538's model would be a gold standard baseline, with only two potential areas for improvement. The first is their CANTOR district similarity, which does not specify how they calculate similarity, but I presume is a cosine similarity based on the features of the district. I believe that a neural embedding trained to minimize reconstruction loss would be better performing, but did not implement this. The second area of improvement is district-specific donation data. 538 noted that they had improved their model since its launch to weight state-level donation data 5x more than national-level donation data. Likely, this is because the more targeted data better understands how many constituents are likely to vote, as opposed to outside financing hoping to sway. I believe the true goal should be limiting to solely constituents, by using district-level data. However, this data is not readily accessible from the FEC, so I created the first approximation (by associating donations with zip codes and zip codes with congressional districts). While I was unable to improve on the 538 model, I believe this data will ultimately be more predictive than state level data.\n",
    "\n",
    "With those main innovations out of the way, let's jump into the details of each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My predictions come from my Lite Model, as my Deluxe model does not improve upon 538."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Republican Two Party Seat Share:** 52.13\\% -> 226.76 Seats -> 227 Seats (40.92\\% - 56.55\\% / 178 - 246 Seats 95\\% Prediction Interval)\n",
    "\n",
    "**Republican Two Party Popular Vote Share:** 50.58\\% (44.43\\% - 53.47\\% 95\\% Prediction Interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lite Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For my lite model, I sought to predict the national two party vote share (of the Republican party) and the national two party vote share (of the Republican party). I used the following features:\n",
    "\n",
    "1. Incumbency\n",
    "- Year of Election\n",
    "- Midterm Year Indicator\n",
    "- Party of the President\n",
    "- 2 Party seat share from the prior election (GOP)\n",
    "- 2 party vote share from the prior election (GOP)\n",
    "2. Economy\n",
    "- Consumer Sentiment Index (absolute value at time of election)\n",
    "- Consumer Sentiment Index (change from start of Congress (Q1 -> Q7 Change))\n",
    "- GDP Growth (annual growth at time of election)\n",
    "- GDP Growth (change from start of Congress (Q1 -> Q7 Change))\n",
    "- RDI Growth (annual growth at time of election)\n",
    "- RDI Growth (change from start of Congress (Q1 -> Q7 Change))\n",
    "3. Polling\n",
    "- Presidential Approval (election year average)\n",
    "- Presidential Approval (Election October & November average)\n",
    "- Generic Congressional Ballot (election year average)\n",
    "- Generic Congressional Ballot (Election October & November average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Incumbency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Year of Election\n",
    "    - My model is based on data since 1978 (due to the availability of consumer sentiment data), during which, the electoral dynamics have changed greatly. Accordingly, this should allow the model to predict the tightening elections of late.\n",
    "    - Example: 2022\n",
    "    - Source: [1948-2022 District-Level Results](lite_data/incumb_dist_1948-2022%20(2).csv)\n",
    "* Midterm Year Indicator\n",
    "    - This is a binary indicator for whether the election is a midterm year, considering that turnout is often lower, and the incumbent party's president tends to lose seats (in every election except 1998 and 2002)\n",
    "    - Example: 1 (if Midterm)\n",
    "    - Source: [1948-2022 District-Level Results](lite_data/incumb_dist_1948-2022%20(2).csv)\n",
    "* Party of the President\n",
    "    - I imagine this to be mostly useful as an interaction term with other variables (e.g. midterm year, presidential approval) to contextualize whether is postitive or negative.\n",
    "    - Example: 1 (if Republican)\n",
    "    - Source: [Wikipedia President List](https://en.wikipedia.org/wiki/List_of_presidents_of_the_United_States), with some [post-processing](./final_prediction_lite.ipynb)\n",
    "* 2 Party seat share from the prior election (GOP)\n",
    "    - Often, elections are viewed more appropriately as seat change given the power of incumbency to set the norm. This should allow to account\n",
    "    - Example: 0.52 (if GOP won 52% of seats won prior election)\n",
    "    - Source: [1948-2022 District-Level Results](lite_data/incumb_dist_1948-2022%20(2).csv)\n",
    "* 2 party vote share from the prior election (GOP)\n",
    "    - Same reasoning as above, but vote share.\n",
    "    - Example: 0.51 (if GOP won 51% of votes won prior election)\n",
    "    - Source: [1948-2022 District-Level Results](lite_data/incumb_dist_1948-2022%20(2).csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Economy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Consumer Sentiment Index (absolute value at time of election)\n",
    "    - As discussed in the introduction, I believe this is a better proxy for consumer perception of the economy than GDP or RDI. I use the latest absolute value at the election's time because of recency bias, and because unlike GDP or RDI, consumer sentiment doesn't need to be normalized as a percent change. \n",
    "    - Example: 78\n",
    "    - Source: [FRED University of Michigan: Consumer Sentiment](https://fred.stlouisfed.org/series/UMCSENT)\n",
    "* Consumer Sentiment Index (change from start of Congress (Q1 -> Q7 Change))\n",
    "    - I view this as less likely than absolute value, but this allows for voters to judge based on overall sentiment of the direction of the economy.\n",
    "    - Example: -2.5\n",
    "    - Source: [FRED University of Michigan: Consumer Sentiment](https://fred.stlouisfed.org/series/UMCSENT) \n",
    "* GDP Growth (annual growth at time of election)\n",
    "    - This is a standard economic indicator, and I believe it is useful to include as a control. This allows for the most recent reading.\n",
    "    - Example: 4.5\n",
    "    - Source: [FRED Real GDP Per Capita](https://fred.stlouisfed.org/series/A939RX0Q048SBEA)\n",
    "* GDP Growth (change from start of Congress (Q1 -> Q7 Change))\n",
    "    - Allows for directional reading of GDP.\n",
    "    - Example: 2.5\n",
    "    - Source: [FRED Real GDP Per Capita](https://fred.stlouisfed.org/series/A939RX0Q048SBEA)\n",
    "* RDI Growth (annual growth at time of election)\n",
    "    - This is a standard economic indicator, and I believe it is useful to include as a control. This allows for the most recent reading.\n",
    "    - Example: 4.5\n",
    "    - Source: [FRED Real Disposable Personal Income: Per Capita](https://fred.stlouisfed.org/series/A229RX0)\n",
    "* RDI Growth (change from start of Congress (Q1 -> Q7 Change))\n",
    "    - Allows for directional reading of RDI.\n",
    "    - Example: 2.5\n",
    "    - Source: [FRED Real Disposable Personal Income: Per Capita](https://fred.stlouisfed.org/series/A229RX0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Presidential Approval (election year average)\n",
    "    - This allows for general sentiment of the president to play into the model.\n",
    "    - Example: 0.6\n",
    "    - Source: For training [Gallup Presidential Approval](lite_data/pres_approval_gallup_1941-2022.csv), For 2022 [538 Biden Approval](https://projects.fivethirtyeight.com/biden-approval-data/approval_polllist.csv) \n",
    "* Presidential Approval (Election October & November average)\n",
    "    - This allows for more recent sentiment of the president to play into the model.\n",
    "    - Example: 0.6\n",
    "    - Source: For training [Gallup Presidential Approval](lite_data/pres_approval_gallup_1941-2022.csv), For 2022, using latest reading on [538 Biden Ratings](https://projects.fivethirtyeight.com/biden-approval-rating/)\n",
    "* Presidential Dispproval (election year average)\n",
    "    - This allows for general sentiment of the president to play into the model.\n",
    "    - Example: 0.4\n",
    "    - Source: For training [Gallup Presidential Approval](lite_data/pres_approval_gallup_1941-2022.csv), For 2022 [538 Biden Approval](https://projects.fivethirtyeight.com/biden-approval-data/approval_polllist.csv) \n",
    "* Presidential Disapproval (Election October & November average)\n",
    "    - This allows for more recent sentiment of the president to play into the model.\n",
    "    - Example: 0.4\n",
    "    - Source: For training [Gallup Presidential Approval](lite_data/pres_approval_gallup_1941-2022.csv), For 2022, using latest reading on [538 Biden Ratings](https://projects.fivethirtyeight.com/biden-approval-rating/)\n",
    "* Generic Congressional Ballot (election year average)\n",
    "    - This allows for general sentiment of the parties to play into the model.\n",
    "    - Example: Dem: 0.41, Rep: 0.42\n",
    "    - Source: For training [Generic Ballot Historical (1942-Present)](lite_data/GenericPolls1942_2020.csv), For 2022 [538 Generic Congressional Ballot](https://projects.fivethirtyeight.com/generic-ballot-data/generic_polllist.csv)\n",
    "* Generic Congressional Ballot (Election October & November average)\n",
    "    - This allows for more recent sentiment of the parties to play into the model.\n",
    "    - Example: Dem: 0.41, Rep: 0.42\n",
    "    - Source: For training [Generic Ballot Historical (1942-Present)](lite_data/GenericPolls1942_2020.csv), For 2022 [538 Generic Congressional Ballot](https://projects.fivethirtyeight.com/polls/data/generic_ballot_averages.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used 4 different model types, each for a different purpose:\n",
    "\n",
    "* Linear Regression\n",
    "    - A baseline model, good for understanding relative and interpretable coefficients\n",
    "* Lasso Regression \n",
    "    - Performs feature selection, good for understanding the most important coefficients.\n",
    "* Polynomial Regression\n",
    "    - Allows for interactions, particularly important for the incumbency features\n",
    "* Random Forest (Ensemble)\n",
    "    - Allows for non-linear interactions, as well as state of the art performance for tabular data (which this is)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an overview of their performance, you can see the following performance data with in sample and out of sample evaluation, including a reference for 2022 which is easy to understand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>R^2</th>\n",
       "      <th>CV Scores</th>\n",
       "      <th>2020 Seat Share Error</th>\n",
       "      <th>2020 Vote Share Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.968144</td>\n",
       "      <td>[-240.07586988   -3.82854943   -2.22217343]</td>\n",
       "      <td>-0.071126</td>\n",
       "      <td>-0.081332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>0.362444</td>\n",
       "      <td>[-23.01198633  -4.22348342   0.04777647]</td>\n",
       "      <td>0.032415</td>\n",
       "      <td>0.000403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>0.933815</td>\n",
       "      <td>[-55.68251395  -3.0316546   -1.31870434]</td>\n",
       "      <td>0.019496</td>\n",
       "      <td>-0.028757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest Regressor (10)</td>\n",
       "      <td>0.848819</td>\n",
       "      <td>[-22.27635859  -8.46810079   0.24039067]</td>\n",
       "      <td>-0.050625</td>\n",
       "      <td>-0.022352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest Regressor (100)</td>\n",
       "      <td>0.905489</td>\n",
       "      <td>[-19.87034581  -5.07148077   0.13054906]</td>\n",
       "      <td>-0.005320</td>\n",
       "      <td>0.002136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest Regressor (1000)</td>\n",
       "      <td>0.909554</td>\n",
       "      <td>[-20.4300514   -4.73017352   0.16471045]</td>\n",
       "      <td>-0.009174</td>\n",
       "      <td>-0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Polynomial Regression (2)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[-8.47923779 -2.15374549 -6.24067355]</td>\n",
       "      <td>-0.035320</td>\n",
       "      <td>-0.052864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Polynomial Regression (3)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[-44.29844793  -2.06639805  -1.49887154]</td>\n",
       "      <td>-0.036479</td>\n",
       "      <td>-0.053570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Polynomial Lasso Regression (2)</td>\n",
       "      <td>0.922338</td>\n",
       "      <td>[-28.30783143  -1.33919337  -2.14168412]</td>\n",
       "      <td>0.020192</td>\n",
       "      <td>-0.013601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Polynomial Lasso Regression (3)</td>\n",
       "      <td>0.999929</td>\n",
       "      <td>[ -9.67270879  -2.88299644 -10.81933603]</td>\n",
       "      <td>-0.056378</td>\n",
       "      <td>-0.065906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              name       R^2  \\\n",
       "0                Linear Regression  0.968144   \n",
       "1                 Lasso Regression  0.362444   \n",
       "2                 Ridge Regression  0.933815   \n",
       "3     Random Forest Regressor (10)  0.848819   \n",
       "4    Random Forest Regressor (100)  0.905489   \n",
       "5   Random Forest Regressor (1000)  0.909554   \n",
       "6        Polynomial Regression (2)  1.000000   \n",
       "7        Polynomial Regression (3)  1.000000   \n",
       "8  Polynomial Lasso Regression (2)  0.922338   \n",
       "9  Polynomial Lasso Regression (3)  0.999929   \n",
       "\n",
       "                                     CV Scores  2020 Seat Share Error  \\\n",
       "0  [-240.07586988   -3.82854943   -2.22217343]              -0.071126   \n",
       "1     [-23.01198633  -4.22348342   0.04777647]               0.032415   \n",
       "2     [-55.68251395  -3.0316546   -1.31870434]               0.019496   \n",
       "3     [-22.27635859  -8.46810079   0.24039067]              -0.050625   \n",
       "4     [-19.87034581  -5.07148077   0.13054906]              -0.005320   \n",
       "5     [-20.4300514   -4.73017352   0.16471045]              -0.009174   \n",
       "6        [-8.47923779 -2.15374549 -6.24067355]              -0.035320   \n",
       "7     [-44.29844793  -2.06639805  -1.49887154]              -0.036479   \n",
       "8     [-28.30783143  -1.33919337  -2.14168412]               0.020192   \n",
       "9     [ -9.67270879  -2.88299644 -10.81933603]              -0.056378   \n",
       "\n",
       "   2020 Vote Share Error  \n",
       "0              -0.081332  \n",
       "1               0.000403  \n",
       "2              -0.028757  \n",
       "3              -0.022352  \n",
       "4               0.002136  \n",
       "5              -0.000029  \n",
       "6              -0.052864  \n",
       "7              -0.053570  \n",
       "8              -0.013601  \n",
       "9              -0.065906  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "model_performance_df = pd.read_csv(\"lite_data/all_model_data.csv\")\n",
    "model_performance_df[[\"name\", \"R^2\", \"CV Scores\", \"2020 Seat Share Error\", \"2020 Vote Share Error\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the goal of linear regression is to get a rough understanding of model coefficients, here is what I found:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With linear regression, we get the following coefficients:\n",
    "\n",
    "year 0.0037737428021888198\n",
    "\n",
    "is_midterm_year 0.034921969446327195\n",
    "\n",
    "rep_pres -0.02982138361770056\n",
    "\n",
    "RepSeatShare_prior -0.7186283376330896\n",
    "\n",
    "RepVoteShare_prior 1.9695919576382186\n",
    "\n",
    "absolute_sentiment -0.0013689150478568136\n",
    "\n",
    "sentiment_change 0.0013559212685174777\n",
    "\n",
    "absolute_gdp 0.0011535946478451894\n",
    "\n",
    "gdp_change 0.5009893745445565\n",
    "\n",
    "rdi 0.012444702538206487\n",
    "\n",
    "rdi_change 0.012444702538211411\n",
    "\n",
    "annual_poll_approval 0.024132311200005422\n",
    "\n",
    "two_month_poll_approval -0.015353670135328549\n",
    "\n",
    "annual_poll_disapproval 0.020252281353538407\n",
    "\n",
    "two_month_poll_disapproval -0.013470520027339098\n",
    "\n",
    "annual_dem 0.014538921653516185\n",
    "\n",
    "two_month_dem -0.01848914678506335\n",
    "\n",
    "annual_rep 0.002119113076802239\n",
    "\n",
    "two_month_rep -0.0012655571198566043"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seemingly, we see that the most important variable is the prior performance, which is good intuitively, and the economic factors, with GDP as the largest coefficient but with other potential collinearities. To get rid of these collinearities, we can use Lasso Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Lasso Regression, we get the following coefficients (for seat share):\n",
    "\n",
    "year 0.0030986477539816475\n",
    "\n",
    "absolute_sentiment 0.0001432172822153464\n",
    "\n",
    "sentiment_change 0.001029068985272151\n",
    "\n",
    "annual_poll_approval 0.0006727147220908171"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the most important economic variables are the sentiment scores, confirming my suspicion, and the presidential approval outweighs generic ballot. This seems promising that the sentiment was a valuable addition.\n",
    "\n",
    "For the vote share, we get the following coefficients:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "year 0.00026173713404008026\n",
    "\n",
    "sentiment_change 0.0003507946764736049"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again showing how ppwerful sentiment is as a predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polynomial Regression\n",
    "\n",
    "For polynomial regression, the coefficients are less interpretable, but importantly, we would expect to see a marked improvement over the linear regression due to the deliberate inclusion of features that allow for interactions (e.g. president party).\n",
    "\n",
    "Indeed we find that the polynomial Lasso Regression greatly improves performance on 2020, as we can imagine that it is only keeping the most important interaction terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, our random forest models give us the state of the art performance given their high degree of non-linearity. Unfortunately, they are much less interpretable, but we can pull generalized feature important (roughly, how often a feature was used as a deciding factor).\n",
    "\n",
    "year 0.1675186669850853\n",
    "\n",
    "is_midterm_year 0.0026796887176913833\n",
    "\n",
    "rep_pres 0.1353620017137392\n",
    "\n",
    "RepSeatShare_prior 0.06888020563584256\n",
    "\n",
    "RepVoteShare_prior 0.0835810571158828\n",
    "\n",
    "absolute_sentiment 0.013916784642159823\n",
    "\n",
    "sentiment_change 0.01591892960535057\n",
    "\n",
    "absolute_gdp 0.010938538229963034\n",
    "\n",
    "gdp_change 0.016124365325747004\n",
    "\n",
    "rdi 0.011846376143070273\n",
    "\n",
    "rdi_change 0.011413370424025366\n",
    "\n",
    "annual_poll_approval 0.0247650251359856\n",
    "\n",
    "two_month_poll_approval 0.022372655026794724\n",
    "\n",
    "annual_poll_disapproval 0.02987771694575475\n",
    "\n",
    "two_month_poll_disapproval 0.034254482187393964\n",
    "\n",
    "annual_dem 0.033116011748911905\n",
    "\n",
    "two_month_dem 0.025373972785702224\n",
    "\n",
    "annual_rep 0.18500667395979925\n",
    "\n",
    "two_month_rep 0.10705347767110034"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Random forest model, there still appears to be some collinearity/confounding factors, as shown with the high important for republican generic polling average and low for the democratic polling average, but importantly, the model picks up on the recent moderation of races and on the importance of incumbency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, we can use the Random Forest to give us a prediction interval based on its structure as 1000 trees based on random subsets of the data. We can thus use these as a set of predictions. Accordingly, the distribution of their outcomes is as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](lite_data/seat_share_hist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest models essentially perform a nearest neighbor search, so you can think of this as showing which prior elections are the most similar to the current -- with the mode notably at a Republican sweep, not at the middle. \n",
    "\n",
    "I used this distribution to create my 95\\% CI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deluxe Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b13879c2d891711983f0da077d4880d94e0fe9173c7d4378500243605826888e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
